{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate and fit a ML model on the EC flux tower data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from scipy import stats\n",
    "from joblib import dump\n",
    "from pprint import pprint\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import shap\n",
    "# from shaphypetune import BoostRFA\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_var = 'NEE'\n",
    "suffix = '20230817'\n",
    "exclusions=['DalyP', 'DalyU', 'RedDi', 'Loxto']\n",
    "variables = ['LST_RS', 'LST-Tair_RS',\n",
    "             'NDVI_RS','NDVI_anom_RS',\n",
    "             # 'NPV_RS','BS_RS', 'PV_RS',\n",
    "             # 'VegH_RS', \n",
    "             'WCF_RS',\n",
    "             'rain_RS', 'rain_anom_RS','rain_cml12_anom_RS','rain_cml3_anom_RS','rain_cml6_anom_RS',\n",
    "             'srad_RS', 'srad_anom_RS', 'tavg_RS', 'tavg_anom_RS', 'vpd_RS',\n",
    "             'site'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip RedDi\n",
      "skip DalyP\n",
      "skip Loxto\n",
      "skip DalyU\n"
     ]
    }
   ],
   "source": [
    "base = '/g/data/os22/chad_tmp/climate-carbon-interactions/results/training_data/'\n",
    "sites = os.listdir('/g/data/os22/chad_tmp/climate-carbon-interactions/results/training_data/')\n",
    "\n",
    "fluxes=['NEE_SOLO_EC','GPP_SOLO_EC','ER_SOLO_EC','ET_EC']\n",
    "\n",
    "td = []\n",
    "for site in sites:\n",
    "    if '.csv' in site:\n",
    "        if any(exc in site for exc in exclusions): #don't load the excluded sites\n",
    "            print('skip', site[0:5])\n",
    "            continue\n",
    "        else:\n",
    "            xx = pd.read_csv(base+site, index_col='time', parse_dates=True)\n",
    "            xx['site'] = site[0:5]\n",
    "            xx = xx[fluxes+variables]\n",
    "            td.append(xx)\n",
    "\n",
    "ts = pd.concat(td).dropna() #we'll use this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3211, 16)\n"
     ]
    }
   ],
   "source": [
    "xx = []\n",
    "yy = []\n",
    "\n",
    "for t in td:\n",
    "    # t = t.drop(['Fluxcom_RS-Meteo_NEE', 'Fluxcom_RS_NEE', 'ThisStudy_NEE', 'Cable_NEE',\n",
    "    #    'Fluxcom_RS_GPP', 'Fluxcom_RS-meteo_GPP', 'ThisStudy_GPP', 'Cable_GPP',\n",
    "    #    'MODIS_GPP', 'GOSIF_GPP'], axis=1)  \n",
    "    \n",
    "    t = t.dropna()  # remove NaNS\n",
    "    df = t.drop(['NEE_SOLO_EC','GPP_SOLO_EC','ER_SOLO_EC'], axis=1) # seperate carbon fluxes\n",
    "    \n",
    "    #df = df.filter(regex='RS') # only use remote sensing variables   \n",
    "    df = df[variables]\n",
    "    \n",
    "    if model_var == 'ET':\n",
    "        df_var=t[model_var+'_EC']\n",
    "    else:\n",
    "        df_var=t[model_var+'_SOLO_EC'] # seperate out the variable we're modelling\n",
    "    \n",
    "    x = df.reset_index(drop=True)#.to_numpy()\n",
    "    y = df_var.reset_index(drop=True)#.to_numpy()\n",
    "    xx.append(x)\n",
    "    yy.append(y)\n",
    "\n",
    "x = pd.concat(xx)\n",
    "y = pd.concat(yy)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model robustness with time-series K-fold cross validation\n",
    "\n",
    "<!-- * If you set boosting as RF then the lightgbm algorithm behaves as random forest. According to the documentation, to use RF you must use bagging_fraction and feature_fraction smaller than 1 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate five sets of train-test indices\n",
    "\n",
    "For each site, grab a sequential set of test samples (time-series-split methods), the remaining points (either side of test samples) go into training.  A single K-fold contains test and training samples from every site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = x['site'].unique()\n",
    "x['original_index'] = [i for i in range(0,len(x))]\n",
    "\n",
    "train_1=[]\n",
    "train_2=[]\n",
    "train_3=[]\n",
    "train_4=[]\n",
    "train_5=[]\n",
    "\n",
    "test_1=[]\n",
    "test_2=[]\n",
    "test_3=[]\n",
    "test_4=[]\n",
    "test_5=[]\n",
    "\n",
    "for site in sites:\n",
    "    df = x.loc[x['site'] == site]\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    i=1\n",
    "    for train, test in tscv.split(df):\n",
    "        all_indices=np.concatenate([train,test])\n",
    "        left_over = df.loc[~df.index.isin(all_indices)].index.values\n",
    "        train = np.concatenate([train, left_over])\n",
    "        if i==1:\n",
    "            train_1.append(df.iloc[train]['original_index'].values)\n",
    "            test_1.append(df.iloc[test]['original_index'].values)\n",
    "        if i==2:\n",
    "            train_2.append(df.iloc[train]['original_index'].values)\n",
    "            test_2.append(df.iloc[test]['original_index'].values)\n",
    "        if i==3:\n",
    "            train_3.append(df.iloc[train]['original_index'].values)\n",
    "            test_3.append(df.iloc[test]['original_index'].values)\n",
    "        if i==4:\n",
    "            train_4.append(df.iloc[train]['original_index'].values)\n",
    "            test_4.append(df.iloc[test]['original_index'].values)\n",
    "        if i==4:\n",
    "            train_5.append(df.iloc[train]['original_index'].values)\n",
    "            test_5.append(df.iloc[test]['original_index'].values)\n",
    "        i+=1\n",
    "\n",
    "train_1 = np.concatenate(train_1)\n",
    "train_2 = np.concatenate(train_2)\n",
    "train_3 = np.concatenate(train_3)\n",
    "train_4 = np.concatenate(train_4)\n",
    "train_5 = np.concatenate(train_5)\n",
    "\n",
    "test_1 = np.concatenate(test_1)\n",
    "test_2 = np.concatenate(test_2)\n",
    "test_3 = np.concatenate(test_3)\n",
    "test_4 = np.concatenate(test_4)\n",
    "test_5 = np.concatenate(test_5)\n",
    "\n",
    "train = [train_1, train_2, train_3, train_4, train_5]\n",
    "test = [test_1, test_2, test_3, test_4, test_5]\n",
    "\n",
    "#check there are no train indices in the test indices\n",
    "for i,j in zip(train, test):\n",
    "    assert (np.sum(np.isin(i,j)) == 0)\n",
    "\n",
    "#remove the columns we no longer need\n",
    "x = x.drop(['site', 'original_index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider using SHAP-based RFA feature selection\n",
    "\n",
    "Ulimately, feature selection was not used as each method gives confliting results, and we don't have too many features anyway.\n",
    "\n",
    "python library: https://github.com/cerlymarco/shap-hypetune\n",
    "\n",
    "Recursive feature addition: https://towardsdatascience.com/recursive-feature-selection-addition-or-elimination-755e5d86a791"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid using distributions\n",
    "param_grid = {\n",
    "    'num_leaves': stats.randint(5,50),\n",
    "    'min_child_samples':stats.randint(10,30),\n",
    "    'boosting_type': ['gbdt', 'dart'],\n",
    "    'max_depth': stats.randint(5,25),\n",
    "    'n_estimators': [200, 300, 400, 500],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out text file of feature layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = open(\"/g/data/os22/chad_tmp/climate-carbon-interactions/results/variables_\"+suffix+\".txt\", \"w\")\n",
    "for element in x.columns:\n",
    "    textfile.write(element + \",\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove features not selected (if using)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x[x.columns[clf.support_]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct nested cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 1/5 outer cv split\r"
     ]
    }
   ],
   "source": [
    "# lists to store results of CV testing\n",
    "acc = []\n",
    "rmse=[]\n",
    "r2=[]\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in zip(train, test):\n",
    "    print(f\"Working on {i}/{len(train)} outer cv split\", end='\\r')\n",
    "    model = LGBMRegressor(random_state=1,\n",
    "                          verbose=-1,\n",
    "                          # monotone_constraints=m_con,\n",
    "                          # monotone_constraints_method='intermediate'\n",
    "                          )\n",
    "\n",
    "    # index training, testing\n",
    "    X_tr, X_tt = x.iloc[train_index, :], x.iloc[test_index, :]\n",
    "    y_tr, y_tt = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #simple random split on inner fold\n",
    "    inner_cv = KFold(n_splits=5,\n",
    "                     shuffle=True,\n",
    "                     random_state=0)\n",
    "    \n",
    "    clf = RandomizedSearchCV(\n",
    "                   model,\n",
    "                   param_grid,\n",
    "                   verbose=0,\n",
    "                   n_iter=100,\n",
    "                   cv=inner_cv.split(X_tr, y_tr)\n",
    "                  )\n",
    "    \n",
    "    #prevents extensive print statements\n",
    "    clf.fit(X_tr, y_tr, callbacks=None)\n",
    "    \n",
    "    # predict using the best model\n",
    "    best_model = clf.best_estimator_\n",
    "    pred = best_model.predict(X_tt)\n",
    "\n",
    "    # evaluate model w/ multiple metrics\n",
    "    # r2\n",
    "    r2_ = r2_score(y_tt, pred)\n",
    "    r2.append(r2_)\n",
    "    # MAE\n",
    "    ac = mean_absolute_error(y_tt, pred)\n",
    "    acc.append(ac)\n",
    "    # RMSE\n",
    "    rmse_ = np.sqrt(mean_squared_error(y_tt, pred))\n",
    "    rmse.append(rmse_)\n",
    "    \n",
    "    #1:1 plots for each fold (save to csv so we can make a plot later on)\n",
    "    df = pd.DataFrame({'Test':y_tt, 'Pred':pred}).reset_index(drop=True)\n",
    "\n",
    "    df.to_csv(\"/g/data/os22/chad_tmp/climate-carbon-interactions/results/cross_val_fluxes/\"+str(i)+\"_\"+model_var+\"_lgbm.csv\")\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print accuracy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean MAE accuracy: \"+ str(round(np.mean(acc), 2)))\n",
    "print(\"Std dev of MAE accuracy: \"+ str(round(np.std(acc), 2)))\n",
    "print('\\n')\n",
    "print(\"Mean RMSE: \"+ str(round(np.mean(rmse), 2)))\n",
    "print(\"Std dev RMSE: \"+ str(round(np.std(rmse), 2)))\n",
    "print('\\n')\n",
    "print(\"Mean r2: \"+ str(round(np.mean(r2), 2)))\n",
    "print(\"Std dev r2: \"+ str(round(np.std(r2), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a single 1:1 plot out of the folds \n",
    "\n",
    "None of the test samples overlap between folds, and every sample has been tested\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffs=[]\n",
    "for i in range(1,len(train)+1):\n",
    "    df = pd.read_csv(f'/g/data/os22/chad_tmp/climate-carbon-interactions/results/cross_val_fluxes/{i}_{model_var}_lgbm.csv', usecols=['Test', 'Pred'])\n",
    "    dffs.append(df)\n",
    "  \n",
    "cross_df = pd.concat(dffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1, figsize=(7,6))\n",
    "\n",
    "xy = np.vstack([cross_df['Test'],cross_df['Pred']])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "sb.scatterplot(data=cross_df, x='Test',y='Pred',c=z, s=50, lw=1, alpha=0.5, ax=ax)\n",
    "sb.regplot(data=cross_df, x='Test',y='Pred', scatter=False, color='darkblue', ax=ax)\n",
    "sb.regplot(data=cross_df, x='Test',y='Test', color='black', scatter=False, line_kws={'linestyle':'dashed'}, ax=ax);\n",
    "\n",
    "plt.xlabel('Observation '+ model_var + ' gC/m\\N{SUPERSCRIPT TWO}/month', fontsize=20)\n",
    "plt.ylabel('Prediction ' + model_var+ ' gC/m\\N{SUPERSCRIPT TWO}/month', fontsize=20)\n",
    "ax.text(.05, .95, 'r\\N{SUPERSCRIPT TWO}={:.2f}'.format(np.mean(r2)),\n",
    "            transform=ax.transAxes, fontsize=20)\n",
    "ax.text(.05, .9, 'MAE={:.3g}'.format(np.mean(acc)),\n",
    "            transform=ax.transAxes, fontsize=20)\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"/g/data/os22/chad_tmp/climate-carbon-interactions/results/cross_val_fluxes/cross_val_\"+model_var+\"_lgbm_\"+suffix+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize model using all training data\n",
    "\n",
    "Using a randomized strategy so we can search through more variables, with 500 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': stats.randint(5,50),\n",
    "    'min_child_samples':stats.randint(10,30),\n",
    "    'boosting_type': ['gbdt', 'dart'],\n",
    "    'max_depth': stats.randint(5,25),\n",
    "    'n_estimators': [300, 400, 500],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomizedSearchCV(LGBMRegressor(verbose=-1),\n",
    "                   param_grid,\n",
    "                   verbose=1,\n",
    "                   n_iter=500,\n",
    "                   cv=zip(train, test), #using timeseries custom splits here\n",
    "                  )\n",
    "\n",
    "clf.fit(x, y, callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The most accurate combination of tested parameters is: \")\n",
    "pprint(clf.best_params_)\n",
    "print('\\n')\n",
    "print(\"The best score using these parameters is: \")\n",
    "print(round(clf.best_score_, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit on all data using best params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(**clf.best_params_)\n",
    "\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model, '/g/data/os22/chad_tmp/climate-carbon-interactions/results/models/fluxes/'+model_var+'_LGBM_model_'+suffix+'.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine feature importance using SHAP\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model\n",
    "\n",
    "https://github.com/slundberg/shap\n",
    "\n",
    "If loading a previously saved model, uncomment the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import load\n",
    "# model_var = 'ER'\n",
    "# suffix = '20230320'\n",
    "# model_path = '/g/data/os22/chad_tmp/NEE_modelling/results/models/AUS_'+model_var+'_LGBM_model_'+suffix+'.joblib'\n",
    "# model = load(model_path).set_params(n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the model's predictions using SHAP\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals= np.abs(shap_values.values).mean(0)\n",
    "feature_importance = pd.DataFrame(list(zip(x.columns, vals)), columns=['col_name','feature_importance_vals'])\n",
    "feature_importance.sort_values(by=['feature_importance_vals'],ascending=False,inplace=True)\n",
    "feature_importance['col_name'] = feature_importance['col_name'].str.removesuffix(\"_RS\")\n",
    "# feature_importance.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(5,11))\n",
    "shap.summary_plot(shap_values, max_display=10, show=False, feature_names=feature_importance['col_name'])\n",
    "plt.gcf().axes[-1].set_aspect('auto')\n",
    "plt.gcf().axes[-1].set_box_aspect(15) \n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "ax.set_xlabel(model_var+' SHAP Value', fontsize=20)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"/g/data/os22/chad_tmp/climate-carbon-interactions/results/cross_val_fluxes/feature_importance_\"+model_var+\"_lgbm_\"+suffix+\".png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency scatter plots (including main interaction effect)\n",
    "\n",
    "showing the effect a single features have on the predictions made by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First plots show the dependence for the top 4 predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font=28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,4, figsize=(32,7))\n",
    "\n",
    "for ax, feature in zip(axs.ravel(), list(feature_importance['col_name'])[0:4]):\n",
    "    shap.plots.scatter(shap_values[:,feature+'_RS'], ax=ax, show=False, color=shap_values, cmap='viridis')\n",
    "    ax.set_ylabel('SHAP value '+ feature,  fontsize=font)\n",
    "    ax.set_xlabel(feature, fontsize=font)\n",
    "    ax.tick_params(axis='x', labelsize=font)\n",
    "    ax.tick_params(axis='y', labelsize=font)\n",
    "    plt.gcf().axes[-2].set_aspect('auto')\n",
    "    plt.gcf().axes[-2].set_box_aspect(20)\n",
    "    plt.gcf().axes[-2].yaxis.label.set_fontsize(font)\n",
    "    plt.gcf().axes[-2].tick_params(axis='y', labelsize=font)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"/g/data/os22/chad_tmp/climate-carbon-interactions/results/cross_val_fluxes/interaction_scatterplots_\"+model_var+\"_lgbm_\"+suffix+\".png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second plots show the dependence for the four main climate predictors (with kNDVI interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,5, figsize=(40,7))\n",
    "\n",
    "for ax, feature, units in zip(axs.ravel(), ['NDVI', 'srad', 'tavg', 'rain', 'vpd'], ['', 'MJ m⁻\\N{SUPERSCRIPT TWO} day⁻¹', '($^\\circ$C)', 'mm/month', 'HPa']): #list(feature_importance['col_name'][0:1])+\n",
    "    if feature =='NDVI':\n",
    "        shap.plots.scatter(shap_values[:,feature+'_RS'], ax=ax, show=False, color=shap_values, cmap='viridis')\n",
    "    else:\n",
    "        shap.plots.scatter(shap_values[:,feature+'_RS'], ax=ax, show=False, color=shap_values[:,'NDVI_RS'], cmap='viridis')\n",
    "        plt.gcf().axes[-2].set_ylabel('NDVI')\n",
    "    ax.set_ylabel(feature+' SHAP values',  fontsize=font)\n",
    "    ax.set_xlabel(feature+', '+units+'', fontsize=font)\n",
    "    ax.tick_params(axis='x', labelsize=font)\n",
    "    ax.tick_params(axis='y', labelsize=font)\n",
    "    plt.gcf().axes[-2].set_aspect('auto')\n",
    "    plt.gcf().axes[-2].set_box_aspect(20)\n",
    "    plt.gcf().axes[-2].yaxis.label.set_fontsize(font)\n",
    "    plt.gcf().axes[-2].tick_params(axis='y', labelsize=font)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"/g/data/os22/chad_tmp/climate-carbon-interactions/results/cross_val_fluxes/interaction_scatterplots_climatevars_\"+model_var+\"_lgbm_\"+suffix+\".png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
