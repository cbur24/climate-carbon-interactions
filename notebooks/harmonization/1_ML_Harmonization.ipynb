{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate AVHRR NDVI to match MODIS NDVI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from joblib import dump\n",
    "from scipy import stats\n",
    "import geopandas as gpd\n",
    "from pprint import pprint\n",
    "from odc.geo.xr import assign_crs\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import shap\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import sys\n",
    "sys.path.append('/g/data/os22/chad_tmp/dea-notebooks/Tools/')\n",
    "from dea_tools.spatial import xr_rasterize\n",
    "\n",
    "sys.path.append('/g/data/os22/chad_tmp/AusEFlux/src/')\n",
    "from _collect_prediction_data import round_coords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_var='LST'\n",
    "n_samples = 30000\n",
    "n_val = 5000\n",
    "name = 'trees'\n",
    "t1 = '1982'\n",
    "t2 = '2013'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble datasets for training and predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean/filter AVHRR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/g/data/os22/chad_tmp/climate-carbon-interactions/data/'+model_var+'_harmonization/AVHRR_'+model_var+'_5km_monthly_1982_2013.nc')\n",
    "ds = assign_crs(ds, crs ='epsg:4326')\n",
    "\n",
    "if model_var=='LST':\n",
    "    ds = ds.rename({'VZA_median':'SZEN_median'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_fraction_avail = (~np.isnan(ds[model_var+'_avhrr'])).sum('time')/len(ds.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter by num of obs/month\n",
    "# ds = ds.where(ds['n_obs']>=2)\n",
    "\n",
    "#remove any very low NDVI vals\n",
    "if model_var=='NDVI':\n",
    "    ds = ds.where(ds[model_var+'_avhrr']>=0.01)\n",
    "\n",
    "# filter by coefficient of variation each month\n",
    "ds[model_var+'_cv'] = ds[model_var+'_stddev'] / ds[model_var+'_avhrr']\n",
    "ds = ds.where(ds[model_var+'_cv']<0.5)\n",
    "\n",
    "#filter by large std dev anomalies\n",
    "def stand_anomalies(ds, clim_mean, clim_std):\n",
    "    std_anom = xr.apply_ufunc(lambda x, m, s: (x - m) / s,\n",
    "    ds.compute().groupby(\"time.month\"),\n",
    "    clim_mean, clim_std)\n",
    "    return std_anom\n",
    "\n",
    "#calculate anomalies\n",
    "clim_std = ds.groupby('time.month').std()\n",
    "clim = ds.groupby('time.month').mean()\n",
    "std_anom = stand_anomalies(ds, clim, clim_std)\n",
    "\n",
    "#create masks where values are < 3.5 stddev >\n",
    "anom_mask = xr.where((std_anom[model_var+'_avhrr'] > -4) & (std_anom[model_var+'_avhrr'] < 4), 1, 0)\n",
    "sza_anom_mask = xr.where((std_anom['SZEN_median'] > -4) & (std_anom['SZEN_median'] < 4), 1, 0)\n",
    "tod_anom_mask = xr.where((std_anom['TIMEOFDAY_median'] > -4) & (std_anom['TIMEOFDAY_median'] < 4), 1, 0)\n",
    "ds = ds.where(anom_mask)\n",
    "ds = ds.where(sza_anom_mask)\n",
    "ds = ds.where(tod_anom_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot available fraction of data before/after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_fraction_avail = (~np.isnan(ds[model_var+'_avhrr'])).sum('time')/len(ds.time)\n",
    "\n",
    "fract_avail_mask = xr.where(before_fraction_avail>0, 1, 0)\n",
    "after_fraction_avail = after_fraction_avail.where(fract_avail_mask)\n",
    "before_fraction_avail = before_fraction_avail.where(fract_avail_mask)\n",
    "\n",
    "fig,ax=plt.subplots(1,2, figsize=(10,4),sharey=True)\n",
    "before_fraction_avail.rename('').plot.imshow(robust=True, ax=ax[0], cmap='magma', add_labels=False)\n",
    "after_fraction_avail.rename('').plot.imshow(robust=True, ax=ax[1], cmap='magma', add_labels=False)\n",
    "ax[0].set_title('Mean Fraction (before): '+str(round(before_fraction_avail.mean().values.item(), 3)));\n",
    "ax[1].set_title('Mean Fraction (after): '+str(round(after_fraction_avail.mean().values.item(), 3)))\n",
    "plt.tight_layout();\n",
    "\n",
    "fig.savefig(\"/g/data/os22/chad_tmp/climate-carbon-interactions/results/figs/AVHRR_\"+model_var+\"_fraction_available.png\",\n",
    "            bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export filtered mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mask = ~np.isnan(ds[model_var+'_avhrr'])\n",
    "filtered_mask = filtered_mask.drop('month')\n",
    "filtered_mask.to_netcdf('/g/data/os22/chad_tmp/climate-carbon-interactions/data/'+model_var+'_harmonization/AVHRR_'+model_var+'_filtered_mask_1982_2013.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add lagged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[model_var+'_avhrr_1f'] = ds[model_var+'_avhrr'].shift(time=1)\n",
    "ds[model_var+'_avhrr_1b'] = ds[model_var+'_avhrr'].shift(time=-1)\n",
    "# ds['NDVI_avhrr_2f'] = ds['NDVI_avhrr'].shift(time=2)\n",
    "# ds['NDVI_avhrr_2b'] = ds['NDVI_avhrr'].shift(time=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.sel(time=slice(t1, t2))\n",
    "ds = ds.drop('month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open covariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/g/data/os22/chad_tmp/climate-carbon-interactions/data/'\n",
    "\n",
    "if model_var=='NDVI':\n",
    "    datasets = [\n",
    "        model_var+'harmonization/MODIS_'+model_var+'_5km_monthly_200003_202212.nc',\n",
    "        '5km/MOY_5km_monthly_1982_2022.nc',\n",
    "        '5km/srad_5km_monthly_1982_2022.nc',\n",
    "        '5km/srad_anom_5km_monthly_1982_2022.nc',\n",
    "        '5km/rain_cml3_5km_monthly_1982_2022.nc',\n",
    "        '5km/rain_cml3_anom_5km_monthly_1982_2022.nc',\n",
    "        # '5km/rain_5km_monthly_1981_2022.nc',\n",
    "        # '5km/rain_cml6_anom_5km_monthly_1982_2022.nc',\n",
    "        # '5km/vpd_5km_monthly_1982_2022.nc',\n",
    "        # '5km/tavg_5km_monthly_1982_2022.nc',\n",
    "        # '5km/tavg_anom_5km_monthly_1982_2022.nc',\n",
    "               ]\n",
    "\n",
    "if model_var=='LST':\n",
    "    datasets = [\n",
    "        model_var+'_harmonization/MODIS_'+model_var+'_5km_monthly_200003_202212.nc',\n",
    "        '5km/MOY_5km_monthly_1982_2022.nc',\n",
    "        '5km/srad_5km_monthly_1982_2022.nc',\n",
    "        '5km/srad_anom_5km_monthly_1982_2022.nc',\n",
    "        # '5km/rain_cml3_5km_monthly_1982_2022.nc',\n",
    "        # '5km/rain_cml3_anom_5km_monthly_1982_2022.nc',\n",
    "        # '5km/rain_5km_monthly_1981_2022.nc',\n",
    "        # '5km/rain_cml6_anom_5km_monthly_1982_2022.nc',\n",
    "        # '5km/vpd_5km_monthly_1982_2022.nc',\n",
    "        '5km/tavg_5km_monthly_1982_2022.nc',\n",
    "        '5km/tavg_anom_5km_monthly_1982_2022.nc',\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = []\n",
    "names = []\n",
    "for d in datasets:\n",
    "    xx =  assign_crs(xr.open_dataset(base+d),crs='epsg:4326').sel(time=slice(t1,t2))\n",
    "    xx = xx.drop('spatial_ref')\n",
    "    names.append(list(xx.data_vars)[0])\n",
    "    dss.append(xx.transpose('time', 'latitude', 'longitude'))\n",
    "\n",
    "covars = xr.merge(dss)\n",
    "covars = assign_crs(covars, crs ='epsg:4326')\n",
    "covars = covars.rename({model_var+'_median':model_var+'_modis'})\n",
    "\n",
    "#merge the AVHR with covariables\n",
    "ds = xr.merge([ds,covars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add some MODIS summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_modis = ds[model_var+'_modis'].mean('time')\n",
    "mean_modis = mean_modis.expand_dims(time=ds.time)\n",
    "ds[model_var+'_modis_mean'] = mean_modis\n",
    "\n",
    "min_modis = ds[model_var+'_modis'].quantile(0.05, dim='time').drop('quantile')\n",
    "min_modis = min_modis.expand_dims(time=ds.time)\n",
    "ds[model_var+'_modis_min'] = min_modis\n",
    "\n",
    "max_modis = ds[model_var+'_modis'].quantile(0.95, dim='time').drop('quantile')\n",
    "max_modis = max_modis.expand_dims(time=ds.time)\n",
    "ds[model_var+'_modis_max'] = max_modis\n",
    "\n",
    "#remove unneeded variables\n",
    "ds = ds.drop([model_var+'_stddev', 'n_obs', model_var+'_cv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add derivative of rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derived = ds['rain'].differentiate(coord='time', datetime_unit='D')\n",
    "# ds['rain_gradient'] = derived\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask for trees/no-trees mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if model_var=='NDVI'\n",
    "trees = xr.open_dataset('/g/data/os22/chad_tmp/climate-carbon-interactions/data/5km/WCF_5km_monthly_1982_2022.nc')['WCF']\n",
    "trees = assign_crs(trees, crs ='epsg:4326')\n",
    "trees = trees.sel(time=slice('2001', '2018'))\n",
    "trees = trees.mean('time')\n",
    "\n",
    "if name=='trees':\n",
    "    mask = xr.where(trees>0.25, 1, 0)\n",
    "if name=='nontrees':\n",
    "    mask = xr.where(trees<=0.25, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.where(filtered_mask) # mask covariables with avhhr filtered\n",
    "ds = ds.where(mask) # mask trees/notrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & testing data: equal random sampling of bioclimatic regions\n",
    "\n",
    "Can skip to importing TD if already run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('/g/data/os22/chad_tmp/NEE_modelling/data/bioclimatic_regions.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to save results \n",
    "results = []\n",
    "for index, row in gdf.iterrows():\n",
    "\n",
    "    if name=='trees':\n",
    "        n=int(n_samples/5)\n",
    "    \n",
    "    if name=='nontrees':\n",
    "        n=int(n_samples/6)\n",
    "        \n",
    "    if (name=='trees') & (row['region_name']=='Desert'):\n",
    "        continue\n",
    "\n",
    "    # else:\n",
    "    print(row['region_name'], n)\n",
    "    \n",
    "    # Generate a polygon mask to keep only data within the polygon\n",
    "    mask = xr_rasterize(gdf.iloc[[index]], ds)\n",
    "    mask = round_coords(mask)\n",
    "    \n",
    "    # Mask dataset to set pixels outside the polygon to `NaN`\n",
    "    dss = ds.sel(time=slice('2000-03','2013')).where(mask)\n",
    "    \n",
    "    #sample equivalent num of samples per region\n",
    "    df = dss.to_dataframe().dropna().sample(n=n, random_state=0).reset_index()\n",
    "    \n",
    "    # Append results to a dictionary using the attribute\n",
    "    # column as an key\n",
    "    results.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(results).reset_index(drop=True)\n",
    "df['year'] = pd.DatetimeIndex(df['time']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['time','spatial_ref'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = df.sample(n=n_val, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(validation.index)\n",
    "print(len(df), 'training samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the location of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "gdf_val = gpd.GeoDataFrame(\n",
    "    validation, geometry=gpd.points_from_xy(validation.longitude, validation.latitude), crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "gdf.to_file('/g/data/os22/chad_tmp/climate-carbon-interactions/data/'+model_var+'_harmonization/'+model_var+'_'+name+'_training_data.geojson')\n",
    "gdf_val.to_file('/g/data/os22/chad_tmp/climate-carbon-interactions/data/'+model_var+'_harmonization/'+model_var+'_'+name+'_validation_data.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.drop(['longitude'], axis=1)\n",
    "gdf_val = gdf_val.drop(['longitude'], axis=1)\n",
    "\n",
    "# gdf.explore(column='year', cmap='inferno')\n",
    "gdf_val.plot(column='year', figsize=(5,5), markersize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = gpd.read_file('/g/data/os22/chad_tmp/climate-carbon-interactions/data/NDVI_harmonization/'+model_var+'_training_data.geojson')\n",
    "# gdf_val = gpd.read_file('/g/data/os22/chad_tmp/climate-carbon-interactions/data/NDVI_harmonization/'+model_var+'_validation_data.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(gdf.drop(columns='geometry', axis=1))\n",
    "validation = pd.DataFrame(gdf_val.drop(columns='geometry', axis=1))\n",
    "\n",
    "df = df.drop(['year'], axis=1)\n",
    "validation = validation.drop(['year'], axis=1)\n",
    "\n",
    "y = df[model_var+'_modis']\n",
    "x = df.drop([model_var+'_modis'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model using nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid using distributions\n",
    "param_grid = {\n",
    "    'num_leaves': stats.randint(5,50),\n",
    "    'min_child_samples':stats.randint(10,30),\n",
    "    'boosting_type': ['gbdt', 'dart'],\n",
    "    'max_depth': stats.randint(5,25),\n",
    "    'n_estimators': [300, 400, 500],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = KFold(n_splits=5, shuffle=True,\n",
    "                   random_state=0)\n",
    "\n",
    "# lists to store results of CV testing\n",
    "acc = []\n",
    "rmse=[]\n",
    "r2=[]\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in outer_cv.split(x, y):\n",
    "    print(f\"Working on {i}/5 outer CV split\", end='\\r')\n",
    "    model = LGBMRegressor(random_state=1,\n",
    "                          verbose=-1,\n",
    "                          # n_jobs=-1\n",
    "                          )\n",
    "\n",
    "    # index training, testing\n",
    "    X_tr, X_tt = x.iloc[train_index, :], x.iloc[test_index, :]\n",
    "    y_tr, y_tt = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #simple random split on inner fold\n",
    "    inner_cv = KFold(n_splits=3,\n",
    "                     shuffle=True,\n",
    "                     random_state=0)\n",
    "    \n",
    "    clf = RandomizedSearchCV(\n",
    "                   model,\n",
    "                   param_grid,\n",
    "                   verbose=0,\n",
    "                   n_iter=50,\n",
    "                   # n_jobs=-1,\n",
    "                   cv=inner_cv.split(X_tr, y_tr)\n",
    "                  )\n",
    "    \n",
    "    #prevents extensive print statements\n",
    "    clf.fit(X_tr, y_tr, callbacks=None)\n",
    "    \n",
    "    # predict using the best model\n",
    "    best_model = clf.best_estimator_\n",
    "    pred = best_model.predict(X_tt)\n",
    "\n",
    "    # evaluate model w/ multiple metrics\n",
    "    # r2\n",
    "    r2_ = r2_score(y_tt, pred)\n",
    "    r2.append(r2_)\n",
    "    # MAE\n",
    "    ac = mean_absolute_error(y_tt, pred)\n",
    "    acc.append(ac)\n",
    "    # RMSE\n",
    "    rmse_ = np.sqrt(mean_squared_error(y_tt, pred))\n",
    "    rmse.append(rmse_)\n",
    "    \n",
    "    #1:1 plots for each fold (save to csv so we can make a plot later on)\n",
    "    df = pd.DataFrame({'Test':y_tt, 'Pred':pred}).reset_index(drop=True)\n",
    "\n",
    "    df.to_csv(\"/g/data/os22/chad_tmp/climate-carbon-interactions/data/\"+model_var+\"_harmonization/cross_validation/\"+str(i)+\"_\"+model_var+\"_lgbm_\"+name+\".csv\")\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a single 1:1 plot out of the folds \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffs=[]\n",
    "for i in range(1,5+1):\n",
    "    df = pd.read_csv(\"/g/data/os22/chad_tmp/climate-carbon-interactions/data/\"+model_var+\"_harmonization/cross_validation/\"+str(i)+\"_\"+model_var+\"_lgbm_\"+name+\".csv\",\n",
    "                     usecols=['Test', 'Pred'])\n",
    "    dffs.append(df)\n",
    "\n",
    "cross_df = pd.concat(dffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1, figsize=(5,5))\n",
    "\n",
    "xy = np.vstack([cross_df['Test'],cross_df['Pred']])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "sb.scatterplot(data=cross_df, x='Test',y='Pred', cmap='magma', c=z, s=10, lw=1, alpha=0.5, ax=ax)\n",
    "sb.regplot(data=cross_df, x='Test',y='Pred', scatter=False, color='darkblue', ax=ax)\n",
    "sb.regplot(data=cross_df, x='Test',y='Test', color='black', scatter=False, line_kws={'linestyle':'dashed'}, ax=ax)\n",
    "# plt.colorbar()\n",
    "plt.xlabel('MODIS '+model_var, fontsize=16)\n",
    "plt.ylabel('Prediction '+model_var, fontsize=16)\n",
    "ax.text(.05, .95, 'r\\N{SUPERSCRIPT TWO}={:.2f}'.format(np.mean(r2)),\n",
    "            transform=ax.transAxes, fontsize=16)\n",
    "ax.text(.05, .9, 'MAE={:.2g}'.format(np.mean(acc)),\n",
    "            transform=ax.transAxes, fontsize=16)\n",
    "\n",
    "if model_var=='NDVI':\n",
    "    ax.set_ylim(0.0, 0.95)\n",
    "    ax.set_xlim(0.0, 0.95)\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"/g/data/os22/chad_tmp/climate-carbon-interactions/data/\"+model_var+\"_harmonization/cross_validation/cross_val_\"+model_var+\"_lgbm_\"+name+\".png\",\n",
    "            bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize model using all training data\n",
    "\n",
    "Using a randomized strategy so we can search through more variables, with 500 iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = KFold(n_splits=5, shuffle=True,\n",
    "                   random_state=0)\n",
    "\n",
    "clf = RandomizedSearchCV(LGBMRegressor(verbose=-1),\n",
    "                   param_grid,\n",
    "                   verbose=1,\n",
    "                   n_iter=250,\n",
    "                   # n_jobs=-1,\n",
    "                   cv=outer_cv\n",
    "                  )\n",
    "\n",
    "clf.fit(x, y, callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The most accurate combination of tested parameters is: \")\n",
    "pprint(clf.best_params_)\n",
    "print('\\n')\n",
    "print(\"The best score using these parameters is: \")\n",
    "print(round(clf.best_score_, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on all data using best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(**clf.best_params_)\n",
    "\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with independent validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = validation[model_var+'_modis']\n",
    "x_val = validation.drop([model_var+'_modis'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_val)\n",
    "\n",
    "r2 = r2_score(y_val, pred)\n",
    "ac = mean_absolute_error(y_val, pred)\n",
    "df_val = pd.DataFrame({'Test':y_val, 'Pred':pred}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1, figsize=(5,5))\n",
    "\n",
    "xy = np.vstack([df_val['Test'],df_val['Pred']])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "sb.scatterplot(data=df_val, x='Test',y='Pred', cmap='magma', c=z, s=20, lw=1, alpha=0.5, ax=ax, legend=True)\n",
    "sb.regplot(data=df_val, x='Test',y='Pred', scatter=False, color='darkblue', ax=ax)\n",
    "sb.regplot(data=df_val, x='Test',y='Test', color='black', scatter=False, line_kws={'linestyle':'dashed'}, ax=ax);\n",
    "\n",
    "plt.xlabel('MODIS '+model_var, fontsize=16)\n",
    "plt.ylabel('Prediction '+model_var, fontsize=16)\n",
    "ax.text(.05, .95, 'R\\N{SUPERSCRIPT TWO}={:.2f}'.format(r2),\n",
    "            transform=ax.transAxes, fontsize=16)\n",
    "ax.text(.05, .9, 'MAE={:.2g}'.format(ac),\n",
    "            transform=ax.transAxes, fontsize=16)\n",
    "\n",
    "if model_var=='NDVI':\n",
    "    ax.set_ylim(0.05, 0.95)\n",
    "    ax.set_xlim(0.05, 0.95)\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"/g/data/os22/chad_tmp/climate-carbon-interactions/data/\"+model_var+\"_harmonization/cross_validation/validation_\"+model_var+\"_lgbm_\"+name+\".png\",\n",
    "            bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model, '/g/data/os22/chad_tmp/climate-carbon-interactions/data/'+model_var+'_harmonization/Harmonization_LGBM_'+name+'.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine feature importance using SHAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the model's predictions using SHAP\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(5,7))\n",
    "shap.plots.violin(shap_values, max_display=10, show=False, plot_type=\"layered_violin\")\n",
    "ax = plt.gca() \n",
    "plt.gcf().axes[-1].set_aspect('auto')\n",
    "plt.gcf().axes[-1].set_box_aspect(15)\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "if name=='trees':\n",
    "    ax.set_xlabel(model_var+ ' \"Trees\" '+'SHAP Value', fontsize=16)\n",
    "    ax.set_xlim(-0.1, 0.1)\n",
    "if name=='nontrees':\n",
    "    ax.set_xlabel(model_var+ ' \"Non-Trees\" '+'SHAP Value', fontsize=16)\n",
    "    ax.set_xlim(-0.2, 0.2)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"/g/data/os22/chad_tmp/climate-carbon-interactions/data/\"+model_var+\"_harmonization/cross_validation/feature_importance_\"+model_var+\"_lgbm_\"+name+\".png\",\n",
    "            bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacube.utils.dask import start_local_dask\n",
    "\n",
    "import sys\n",
    "sys.path.append('/g/data/os22/chad_tmp/dea-notebooks/Tools/')\n",
    "from dea_tools.classification import predict_xr, HiddenPrints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = start_local_dask(mem_safety_margin='2Gb')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load('/g/data/os22/chad_tmp/climate-carbon-interactions/data/NDVI_harmonization/Harmonization_LGBM_'+name+'.joblib').set_params(n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add lat as a variable\n",
    "\n",
    "Plus ensure order of the variables is correct for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ds.latitude\n",
    "y = y.expand_dims(time=ds.time, longitude=ds.longitude)\n",
    "y = y.transpose('time', 'latitude', 'longitude')\n",
    "ds['latitude_data'] = y\n",
    "\n",
    "# lon = ds.longitude\n",
    "# lon = lon.expand_dims(time=ds.time, latitude=ds.latitude)\n",
    "# lon = lon.transpose('time', 'latitude', 'longitude')\n",
    "# ds['longitude_gridded'] = lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure features match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(ds.data_vars)[:-1]\n",
    "columns.insert(0, 'latitude_data')\n",
    "ds = ds[columns]\n",
    "ds = ds.drop(model_var+'_modis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vars = list(x.columns)\n",
    "train_vars[0] = 'latitude_data'\n",
    "\n",
    "if train_vars == list(ds.data_vars):\n",
    "    print('Variables match, n: ', len(ds.data_vars))\n",
    "else:\n",
    "    raise ValueError('Variables dont match')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-create the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = xr.open_dataset('/g/data/os22/chad_tmp/climate-carbon-interactions/data/5km/WCF_5km_monthly_1982_2022.nc')['WCF']\n",
    "trees = assign_crs(trees, crs ='epsg:4326')\n",
    "trees=trees.sel(time=slice('2001', '2018'))\n",
    "trees = trees.mean('time')\n",
    "\n",
    "if name=='trees':\n",
    "    mask = xr.where(trees>0.25, 1, 0)\n",
    "if name=='nontrees':\n",
    "    mask = xr.where(trees<=0.25, 1, 0)\n",
    "\n",
    "#rename so predict_xr is happy\n",
    "ds = ds.rename({'latitude':'y', 'longitude':'x'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "results = []\n",
    "i=0\n",
    "for i in range(0, len(ds.time)):\n",
    "    print(\" {:03}/{:03}\\r\".format(i + 1, len(range(0, len(ds.time)))), end=\"\")\n",
    "    with HiddenPrints():\n",
    "        predicted = predict_xr(model,\n",
    "                            ds.isel(time=i).drop('time'),\n",
    "                            proba=False,\n",
    "                            clean=True,\n",
    "                            chunk_size=100000,\n",
    "                              ).compute()\n",
    "    \n",
    "    # predicted = predicted.Predictions.where(~mask.isel(time=i))\n",
    "    predicted = predicted.assign_coords(time=ds.isel(time=i).time).expand_dims(time=1)\n",
    "    results.append(predicted.astype('float32'))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = xr.concat(results, dim='time').sortby('time').rename({'Predictions':model_var})#.astype('float32')\n",
    "yy = yy.where(mask.rename({'latitude':'y', 'longitude':'x'}))\n",
    "yy = yy.where(filtered_mask.rename({'latitude':'y', 'longitude':'x'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy.to_netcdf('/g/data/os22/chad_tmp/climate-carbon-interactions/data/'+model_var+'_harmonization/'+model_var+'_'+name+'_LGBM_harmonize_5km_monthly_1982_2013.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy[model_var].mean(['x', 'y']).plot(figsize=(11,4))\n",
    "# plt.ylim(0.2,0.38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1619aa7c0a0d41f892bc55d700874aba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ef7c7b47129f4bb7be210a31c9c6748c",
       "style": "IPY_MODEL_6c45957fae8a4c9c90d0efa71fb7acd3",
       "value": "100%"
      }
     },
     "1b9dd35d726a487c9e03b50cadec204e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "27c2edfba16545549cbc2446f65308f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "43e325ac2f4b42659d9ae321464c5dd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_9b47cb4d6d96465b8a2446bc022c085d",
       "max": 217,
       "style": "IPY_MODEL_27c2edfba16545549cbc2446f65308f9",
       "value": 217
      }
     },
     "5ce2388f84c64f1eb830509fab75e200": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1619aa7c0a0d41f892bc55d700874aba",
        "IPY_MODEL_43e325ac2f4b42659d9ae321464c5dd1",
        "IPY_MODEL_e6391b33874b4787837251849ceb2b1c"
       ],
       "layout": "IPY_MODEL_cc67c362ea5f4f80bfa29df7189ad3e6"
      }
     },
     "6c45957fae8a4c9c90d0efa71fb7acd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "91df15d5486440d6a2125e74e9befe48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9b47cb4d6d96465b8a2446bc022c085d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cc67c362ea5f4f80bfa29df7189ad3e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e6391b33874b4787837251849ceb2b1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1b9dd35d726a487c9e03b50cadec204e",
       "style": "IPY_MODEL_91df15d5486440d6a2125e74e9befe48",
       "value": " 217/217 [01:53&lt;00:00,  2.18it/s]"
      }
     },
     "ef7c7b47129f4bb7be210a31c9c6748c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
